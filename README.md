🧪 实验环境（Environment）

Torch: 1.10.2+cpu

Scikit-learn: 0.24.2

NumPy: 1.19.5

TensorFlow: 2.6.2

Pandas: 1.1.5

📊 实验背景与目的（Background & Objective）
随着软件系统复杂度的提升，构件化开发因其可复用性与高效性成为主流开发方法。构件链预测作为辅助开发的重要一环，可减少重复劳动并提高构件选择效率。
本研究尝试利用深度学习模型（特别是 TCN）对构件组合进行建模与预测，提升开发者的构建效率与准确性。

📁 数据集简介（Dataset）
来源：核格集成开发平台项目中的 .pix 文件，转换为 .xml 格式

内容：通过解析 XML 获取构件调用链，处理后构成构件链表格

数据处理方法包括：遍历 XML 节点、处理分支/循环节点、替代无效构件、自定义构件映射等

⚙️ 数据预处理（Data Preprocessing）
构件链文本 → 数值序列（Tokenizer 编码）

输入样本：去除最后一项

标签：每条链的最后一个构件

填充：统一输入序列长度

数据划分：训练集与测试集按 7:3 划分，最终保存为 .pth 文件

🧩 模型对比（Model Comparison）
比较模型包括：

| 模型      | Loss（测试）     | Accuracy（测试） | Precision  | Recall     | F1 Score   |
| ------- | ------------ | ------------ | ---------- | ---------- | ---------- |
| BiLSTM  | 0.097740     | 0.964707     | 0.7990     | 0.5757     | 0.8156     |
| LSTM    | 0.117565     | 0.968642     | 0.9481     | 0.3713     | 0.8416     |
| RNN     | 0.216917     | 0.924594     | 0.3981     | 0.0088     | 0.5695     |
| **TCN** | **0.063455** | **0.980049** | **0.9341** | **0.6647** | **0.8984** |

TCN（Temporal Convolutional Network）在多个指标上表现最优，因此被选为最终模型。

改进后的TCN网络结构

为进一步提升性能，设计了集成GRU模块、注意力阈值层（AttentionZeroedLayer）和Chomp1d层的改进型TCN结构：

模块功能说明：

Embedding Layer：将构件ID转为稠密向量，捕捉构件之间的语义关系。

GRU单元：增强模型对构件序列中长期依赖的建模能力，减少梯度消失。

AttentionZeroedLayer：通过可学习注意力权重，对输入值进行动态稀疏化，过滤掉不重要的构件信息。

Chomp1d：维持序列长度一致性，避免时间信息泄露。

改进后的 TCN 模型表现如下：

指标	值
Loss	0.0329
Accuracy	0.9913
Precision	0.9797
Recall	0.8192
F1-Score	0.9553

结论：与原始TCN模型相比，加入GRU与注意力稀疏机制后，在保持准确率的同时，召回率显著提升，提高了模型对构件使用模式的覆盖能力。

✅ 最终结论（Conclusion）
TCN 模型在构件链预测任务中表现出色，能够有效辅助构件化软件开发中的智能推荐，为开发者提供更高效的开发体验。本项目为后续构件推荐系统的开发奠定基础。

